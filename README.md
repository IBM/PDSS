# Property-driven localization and characterization in deep molecular representations

Representation learning via pre-trained deep learning models is emerging as an integral method for studying the molecular structure-property relationship, which is then leveraged to predict molecular properties or design new molecules with desired attributes.   
We propose an unsupervised method to localize and characterize representations of pre-trained models through the lens of non-parametric property-driven subset scanning (PDSS), to improve the interpretability of deep molecular representations.
We assess its detection capabilities on diverse molecular benchmarks (ZINC-250K, MOSES, MoleculeNet, FlavorDB, M2OR) across predictive chemical language models (MoLFormer, ChemBERTa) and molecular graph generative models (GraphAF, GCPN). We further study how representations evolve due to domain adaptation, and we evaluate the usefulness of the extracted property-driven elements in the embeddings as lower-dimension representations for downstream tasks.  
Experiments reveal notable information condensation in the pre-trained embeddings upon task-specific fine-tuning.
For example, among the property-driven elements found in the embedding (out of $\approx 700$), only $11$ are shared between three distinct tasks (BACE, BBBP, and HIV), while $\approx 70-80$ of those are unique to each task. Similar patterns are found for flavor and odor detection tasks. 
When we use the discovered property-driven elements as features for a new task, we find the same or improved performance ($3$ points up) while reducing the dimensions by $75$% without fine-tuning required, thus indicating information localization. 


## Repo organization

- See [this yaml](./env.yaml) to define the parameters to run the [ploomber pipeline](https://ploomber.io/) example with bbbp-finetuned embeddings (eg. model name, dataset, number of test samples, scoring function to use, etc).
- See [this file](./pipeline.yaml) and [this folder](./tasks) to check the structure and code to run the full pipeline, from loading the activations, split the test samples, run PDSS and visualize results.
- See [this folder](./output/molformer/bbbp_finetune/) for an example output of ipynb generated by running the `$ ploomber build --force` with the current setup.



## Citation

TBD

## Setup 


For this repo, we used *Python 3.10.14* and dependencies are listed in *requirements.txt*

`$ python -m venv pdssenv` or `$ python3.10 -m venv pdssenv`

`$ source pdssenv/bin/activate`

`$ pip install -r requirements.txt`

`$ ploomber build --force  `
